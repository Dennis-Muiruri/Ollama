# Ollama

docker exec -it open-webui bash 

# Install virtualenv if itâ€™s not installed
pip install virtualenv

# Create the virtual environment (name it myenv or anything you prefer)
virtualenv myenv


# Activate the virtual environment (Linux or macOS)
source myenv/bin/activate


llama model download --source huggingface --model-id Llama3.2-90B-Vision



docker exec -it <container_name> bash
ls /path/to/your/llama/models


https://llama3-2-multimodal.llamameta.net/*?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoidmpkMmFtZnY0MTJ3d2poN2FsZnp5ejVqIiwiUmVzb3VyY2UiOiJodHRwczpcL1wvbGxhbWEzLTItbXVsdGltb2RhbC5sbGFtYW1ldGEubmV0XC8qIiwiQ29uZGl0aW9uIjp7IkRhdGVMZXNzVGhhbiI6eyJBV1M6RXBvY2hUaW1lIjoxNzMxNjg0MDUwfX19XX0_&Signature=KUnZBwM-7TCuj9jFccrTEnRv7uhsQ2Ar4Lq%7ELRHHsyvd7rkvVhokxLYzpH0qyOEQpjc-kSzFtuPrFkVaJxcNHlh9Rd9DkLTKxrVtU45Ij8LkZ2%7E-%7EF8T%7EfbBE47As1Qx9fA07A5z7vXUWLQP%7Ensba9Tvcmp-mQThZ1RvbjqJ6P6t59gOS6XJ8fGj17Gh4gRhcG%7EJtvkzbPSfECUpu9dM4uvFFyd-WElNGsuKPVT8gZsKPDamGfL7VvtVjd%7Eq7y2R47Uh2ekBUygPJMK8kDnsAvDvMG8rAh1U1qsoVMdagjIZmKjmKmrPbpOUGAOWZdtKCQz76mmgtTg4CuaReJhM6g__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=1533084477323600
